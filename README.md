# Take Home Assignment â€“ Machine Learning (PII Violation Detection)

## ğŸš€ Project Overview

This project was developed for a take-home assignment that requires building a machine learning system capable of **automatically flagging Personally Identifiable Information (PII)** in either text or image data.

The system supports:
- Two modalities: **Text (BERT)** and **Image (ResNet18)**
- Unified data format for both types
- Record-level binary classification
- Evaluation using realistic public datasets

---

## ğŸ“˜ Assignment Task Summary

> You are given records in the format `Data(dataset_id, id, value, flag)`. Your model must predict `flag = 1` when the `value` potentially violates privacy, based on either textual or visual content.

Requirements:
- Support at least one modality
- `flag = 1` for sensitive content
- Simulated or real datasets allowed

---

## ğŸ—‚ï¸ Folder Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ data_image/
â”‚   â”œâ”€â”€ 0/                        # Non-PII images
â”‚   â”œâ”€â”€ 1/                        # PII images
â”‚   â””â”€â”€ preprocessed_images.json
â”œâ”€â”€ data_nlp/
â”‚   â”œâ”€â”€ preprocessed_train.json
â”‚   â”œâ”€â”€ splited_train.json
â”‚   â”œâ”€â”€ splited_test.json
â”‚   â””â”€â”€ dataset_metadata.json
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ 0/                        # Trained BERT model
â”‚   â””â”€â”€ 1/                        # Trained ResNet model
â”œâ”€â”€ main_training.py             # Training script
â”œâ”€â”€ main_inference.py            # Evaluation script
â”œâ”€â”€ preprocess_nlp.py            # Preprocess TLAL dataset
â”œâ”€â”€ split_text_dataset.py        # Stratified text split
â”œâ”€â”€ download_images.py           # Download OpenImages
â”œâ”€â”€ model_bert.py                # BERT wrapper
â”œâ”€â”€ model_resnet.py              # ResNet wrapper
â”œâ”€â”€ requirements.txt
â””â”€â”€ utils.py
```

---

## ğŸ“ Datasets Used

### 1. Text Modality â€“ TLAL Dataset (Kaggle)

- Source: [Kaggle PII Detection Challenge](https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data)
- Essays from MOOC students with token-level BIO labels

#### Preprocessing

```bash
python preprocess_nlp.py
python split_text_dataset.py
```

- Converts token labels to `flag = 1` if any token is PII
- Produces `preprocessed_train.json`, then stratified into `splited_train.json` and `splited_test.json`

Example:
```json
{ "dataset_id": 1, "id": 7, "value": "My name is John", "flag": 1 }
```

---

### 2. Image Modality â€“ OpenImages V6

- Source: [OpenImages Dataset](https://storage.googleapis.com/openimages/web/index.html)
- Simulates visual PII (e.g., person vs. cat)

#### Labels

| Flag | Classes                        |
|------|--------------------------------|
| 1    | Person, Man, Woman             |
| 0    | Cat, Dog, Furniture, Tool      |

#### Preprocessing

```bash
python download_images.py
```

- Downloads 150 images per class
- Generates `preprocessed_images.json`

Example:
```json
{ "dataset_id": 2, "id": 45, "value": "data_image/1/person_23.jpg", "flag": 1 }
```

---

## ğŸ’¾ Quick Start (Prebuilt Data & Models)

ğŸ“¦ Download everything preprocessed:  
[**all_data.zip**](https://drive.google.com/file/d/1NjFN8QbQaTaR1KADrj3CacImxnUY6JJu/view?usp=sharing)

```bash
unzip all_data.zip
```

This creates:
```
data_nlp/
data_image/
models/
```

No need to run preprocessing or training.

---

## ğŸ§° Installation

```bash
pip install -r requirements.txt
```

Key packages:
- `transformers`, `datasets`, `torch`, `torchvision`
- `scikit-learn`, `click`, `pandas`, `tqdm`, `Pillow`

---

## ğŸ‹ï¸ Training

To train a new model:

```bash
python main_training.py --model bert
python main_training.py --model resnet
```

- Automatically saved under `models/{n}/` with `metadata.json` and model files

---

## âœ… Evaluation

Run evaluation on trained models:

```bash
python main_inference.py --type nlp --model-dir models/0
python main_inference.py --type image --model-dir models/1
```

---

## ğŸ“Š Evaluation Results

### Text â€“ BERT (Model ID 0)

```bash
python main_inference.py --type nlp --model-dir models/0
```

```
Evaluation Report (NLP Model):
              precision    recall  f1-score   support
      No PII     0.9757    0.9906    0.9831      1173
         PII     0.9357    0.8466    0.8889       189
    accuracy                         0.9706      1362
   macro avg     0.9557    0.9186    0.9360      1362
weighted avg     0.9701    0.9706    0.9700      1362
```

---

### Image â€“ ResNet18 (Model ID 1)

```bash
python main_inference.py --type image --model-dir models/1
```

```
Evaluation Report (Image Model):
              precision    recall  f1-score   support
      No PII     0.9886    0.9667    0.9775        90
         PII     0.9674    0.9889    0.9780        90
    accuracy                         0.9778       180
   macro avg     0.9780    0.9778    0.9778       180
weighted avg     0.9780    0.9778    0.9778       180
```

---

## ğŸ§¾ Summary Table

| Model ID | Modality | Accuracy | Macro F1 | Dataset       |
|----------|----------|----------|----------|---------------|
| `0`      | Text     | 97.1%    | 0.9360   | TLAL (Kaggle) |
| `1`      | Image    | 97.8%    | 0.9778   | OpenImages    |

---

## ğŸ”® Future Directions

- **Containerization**: Package the pipelines into Docker containers for easier deployment, reproducibility, and integration into real-time services via REST APIs.

- **Fine-Grained Detection**: Extend the models to pinpoint the exact source of PII â€” token-level highlighting for text and bounding boxes for images using object detection architectures like YOLO or Faster R-CNN.

- **Multimodal Fusion**: Combine both modalities for documents or AI-generated outputs that mix text and image.

- **Data Augmentation**: Improve generalization by generating synthetic PII samples (names, IDs, faces) in both modalities.

- **Explainability Tools**: Use interpretability frameworks like SHAP or attention heatmaps to increase model transparency.

---

## ğŸ“¬ Contact

ğŸ“§ sdghafouri@gmail.com
